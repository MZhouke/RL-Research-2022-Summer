{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Environment Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initialize(instance_path):\n",
    "    \"\"\"\n",
    "        populate job_operation_map using the instance file input\n",
    "        :param instance_path: a string representing file path\n",
    "    \"\"\"\n",
    "    # input instance description for environment initialization\n",
    "    instance_path = instance_path\n",
    "    try:\n",
    "        file_handle = open(instance_path, 'r')\n",
    "    except OSError:\n",
    "        print(\"Could not open/read file:\", instance_path)\n",
    "\n",
    "    lines_list = file_handle.readlines()\n",
    "    job_operation_map = []\n",
    "    # first line consists of # of jobs in total, # of machines in total\n",
    "    job_total, machine_total = [int(x) for x in lines_list[0].split()]\n",
    "    # read through each job description\n",
    "    for job_index in range(len(lines_list) - 1):\n",
    "        job_description = np.array([int(val) for val in lines_list[job_index + 1].split()])\n",
    "        job_operation_map.append([])\n",
    "        # populate job_description_map\n",
    "        job_operation_map[job_index] = populate_job_description_map(job_description, job_index)\n",
    "    file_handle.close()\n",
    "    return job_operation_map, job_total, machine_total\n",
    "\n",
    "def populate_job_description_map(job_description, job_index):\n",
    "    \"\"\"\n",
    "        populate the corresponding fields in job_description_map\n",
    "        :param job_description: a string representing job description\n",
    "        :param job_index: an integer representing current job index being populated\n",
    "    \"\"\"\n",
    "    job_array = []\n",
    "    # read job description from left to right\n",
    "    description_pivot = 1\n",
    "    operation_index = 0\n",
    "    # operation_index\n",
    "    while description_pivot < len(job_description):\n",
    "        operation_array = []\n",
    "        # operation_description length = 2 * # of machines capable of executing current operation at the pivot\n",
    "        operation_description_end = 2 * job_description[description_pivot] + description_pivot\n",
    "        # read the current description of operation\n",
    "        description_pivot += 1\n",
    "        while description_pivot <= operation_description_end:\n",
    "            # Following the format of operation description:\n",
    "            # machine index , time it takes for the current operation\n",
    "            machine_index = job_description[description_pivot]\n",
    "            operation_duration = job_description[description_pivot + 1]\n",
    "            operation_array.append((operation_duration, machine_index))\n",
    "            description_pivot += 2\n",
    "        operation_index += 1\n",
    "        job_array.append(operation_array)\n",
    "    return job_array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_s, job_total_s, machine_total_s = initialize(\"../Instances/instance1.txt\")\n",
    "env_m, job_total_m, machine_total_m = initialize(\"../Instances/instance5.txt\")\n",
    "env_l, job_total_l, machine_total_l = initialize(\"../Instances/instance4.txt\")\n",
    "env_xl, job_total_xl, machine_total_xl = initialize(\"../Instances/instance3.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_names = [\"Small\", \"Medium\", \"Large\", \"Extra Large\"]\n",
    "env_list = [env_s, env_m, env_l, env_xl]\n",
    "job_total_list = [job_total_s, job_total_m, job_total_l, job_total_xl]\n",
    "machine_total_list = [machine_total_s, machine_total_m, machine_total_l, machine_total_xl]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class SolutionPrinter(cp_model.CpSolverSolutionCallback):\n",
    "    \"\"\"Print intermediate solutions.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        cp_model.CpSolverSolutionCallback.__init__(self)\n",
    "        self.__solution_count = 0\n",
    "\n",
    "    def on_solution_callback(self):\n",
    "        \"\"\"Called at each new solution.\"\"\"\n",
    "        # print('Solution %i, time = %f s, objective = %i' %\n",
    "        #       (self.__solution_count, self.WallTime(), self.ObjectiveValue()))\n",
    "        self.__solution_count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flexible_jobshop(job_operation_map, job_total, machine_total, print_solution = False):\n",
    "    \"\"\"Solve a small flexible jobshop problem.\"\"\"\n",
    "    # Data part.\n",
    "    jobs = job_operation_map\n",
    "\n",
    "    num_jobs = job_total\n",
    "    all_jobs = range(num_jobs)\n",
    "\n",
    "    num_machines = machine_total\n",
    "    all_machines = range(num_machines)\n",
    "\n",
    "    # Model the flexible jobshop problem.\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    horizon = 0\n",
    "    for job in jobs:\n",
    "        for task in job:\n",
    "            max_task_duration = 0\n",
    "            for alternative in task:\n",
    "                max_task_duration = max(max_task_duration, alternative[0])\n",
    "            horizon += max_task_duration\n",
    "\n",
    "    # print('Horizon = %i' % horizon)\n",
    "\n",
    "    # Global storage of variables.\n",
    "    intervals_per_resources = collections.defaultdict(list)\n",
    "    starts = {}  # indexed by (job_id, task_id).\n",
    "    presences = {}  # indexed by (job_id, task_id, alt_id).\n",
    "    job_ends = []\n",
    "\n",
    "    # Scan the jobs and create the relevant variables and intervals.\n",
    "    for job_id in all_jobs:\n",
    "        job = jobs[job_id]\n",
    "        num_tasks = len(job)\n",
    "        previous_end = None\n",
    "        for task_id in range(num_tasks):\n",
    "            task = job[task_id]\n",
    "\n",
    "            min_duration = task[0][0]\n",
    "            max_duration = task[0][0]\n",
    "\n",
    "            num_alternatives = len(task)\n",
    "            all_alternatives = range(num_alternatives)\n",
    "\n",
    "            for alt_id in range(1, num_alternatives):\n",
    "                alt_duration = task[alt_id][0]\n",
    "                min_duration = min(min_duration, alt_duration)\n",
    "                max_duration = max(max_duration, alt_duration)\n",
    "\n",
    "            # Create main interval for the task.\n",
    "            suffix_name = '_j%i_t%i' % (job_id, task_id)\n",
    "            start = model.NewIntVar(0, horizon, 'start' + suffix_name)\n",
    "            duration = model.NewIntVar(min_duration, max_duration,\n",
    "                                       'duration' + suffix_name)\n",
    "            end = model.NewIntVar(0, horizon, 'end' + suffix_name)\n",
    "            interval = model.NewIntervalVar(start, duration, end,\n",
    "                                            'interval' + suffix_name)\n",
    "\n",
    "            # Store the start for the solution.\n",
    "            starts[(job_id, task_id)] = start\n",
    "\n",
    "            # Add precedence with previous task in the same job.\n",
    "            if previous_end is not None:\n",
    "                model.Add(start >= previous_end)\n",
    "            previous_end = end\n",
    "\n",
    "            # Create alternative intervals.\n",
    "            if num_alternatives > 1:\n",
    "                l_presences = []\n",
    "                for alt_id in all_alternatives:\n",
    "                    alt_suffix = '_j%i_t%i_a%i' % (job_id, task_id, alt_id)\n",
    "                    l_presence = model.NewBoolVar('presence' + alt_suffix)\n",
    "                    l_start = model.NewIntVar(0, horizon, 'start' + alt_suffix)\n",
    "                    l_duration = task[alt_id][0]\n",
    "                    l_end = model.NewIntVar(0, horizon, 'end' + alt_suffix)\n",
    "                    l_interval = model.NewOptionalIntervalVar(\n",
    "                        l_start, l_duration, l_end, l_presence,\n",
    "                        'interval' + alt_suffix)\n",
    "                    l_presences.append(l_presence)\n",
    "\n",
    "                    # Link the primary/global variables with the local ones.\n",
    "                    model.Add(start == l_start).OnlyEnforceIf(l_presence)\n",
    "                    model.Add(duration == l_duration).OnlyEnforceIf(l_presence)\n",
    "                    model.Add(end == l_end).OnlyEnforceIf(l_presence)\n",
    "\n",
    "                    # Add the local interval to the right machine.\n",
    "                    intervals_per_resources[task[alt_id][1]].append(l_interval)\n",
    "\n",
    "                    # Store the presences for the solution.\n",
    "                    presences[(job_id, task_id, alt_id)] = l_presence\n",
    "\n",
    "                # Select exactly one presence variable.\n",
    "                model.AddExactlyOne(l_presences)\n",
    "            else:\n",
    "                intervals_per_resources[task[0][1]].append(interval)\n",
    "                presences[(job_id, task_id, 0)] = model.NewConstant(1)\n",
    "\n",
    "        job_ends.append(previous_end)\n",
    "\n",
    "    # Create machines constraints.\n",
    "    for machine_id in all_machines:\n",
    "        intervals = intervals_per_resources[machine_id]\n",
    "        if len(intervals) > 1:\n",
    "            model.AddNoOverlap(intervals)\n",
    "\n",
    "    # Makespan objective\n",
    "    makespan = model.NewIntVar(0, horizon, 'makespan')\n",
    "    model.AddMaxEquality(makespan, job_ends)\n",
    "    model.Minimize(makespan)\n",
    "\n",
    "    # Solve model.\n",
    "    solver = cp_model.CpSolver()\n",
    "    solution_printer = SolutionPrinter()\n",
    "    status = solver.Solve(model, solution_printer)\n",
    "\n",
    "    if print_solution:\n",
    "        # Print final solution.\n",
    "        for job_id in all_jobs:\n",
    "            print('Job %i:' % job_id)\n",
    "            for task_id in range(len(jobs[job_id])):\n",
    "                start_value = solver.Value(starts[(job_id, task_id)])\n",
    "                machine = -1\n",
    "                duration = -1\n",
    "                selected = -1\n",
    "                for alt_id in range(len(jobs[job_id][task_id])):\n",
    "                    if solver.Value(presences[(job_id, task_id, alt_id)]):\n",
    "                        duration = jobs[job_id][task_id][alt_id][0]\n",
    "                        machine = jobs[job_id][task_id][alt_id][1]\n",
    "                        selected = alt_id\n",
    "                print(\n",
    "                    '  task_%i_%i starts at %i (alt %i, machine %i, duration %i)' %\n",
    "                    (job_id, task_id, start_value, selected, machine, duration))\n",
    "\n",
    "    # print('Solve status: %s' % solver.StatusName(status))\n",
    "    print('Optimal makespan: %i' % solver.ObjectiveValue())\n",
    "    # print('Statistics')\n",
    "    # print('  - conflicts : %i' % solver.NumConflicts())\n",
    "    # print('  - branches  : %i' % solver.NumBranches())\n",
    "    # print('  - wall time : %f s' % solver.WallTime())\n",
    "    return solver.ObjectiveValue()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found by OR-Tools for Small environment\n",
      "Optimal makespan: 53\n",
      "Solution found by OR-Tools for Medium environment\n",
      "Optimal makespan: 55\n",
      "Solution found by OR-Tools for Large environment\n",
      "Optimal makespan: 40\n",
      "Solution found by OR-Tools for Extra Large environment\n",
      "Optimal makespan: 927\n"
     ]
    }
   ],
   "source": [
    "solutions_rs = [0]*4\n",
    "for i in range(4):\n",
    "    print('Solution found by OR-Tools for {} environment'.format(env_names[i]))\n",
    "    solutions_rs[i] = flexible_jobshop(env_list[i], job_total_list[i], machine_total_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}